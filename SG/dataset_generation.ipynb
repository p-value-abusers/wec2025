{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2590bca7",
   "metadata": {},
   "source": [
    "# aggregation of neighbourhood for each station from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c1c8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "traffic_data_train = pd.read_parquet(\"../for_participants/data_parquet/traffic_train.parquet\")\n",
    "traffic_data_test = pd.read_parquet(\"../for_participants/data_parquet/traffic_test_without_target.parquet\")\n",
    "pois_df = pd.read_parquet(\"../for_participants/data_parquet/pois.parquet\")\n",
    "demo_df = pd.read_parquet('../for_participants/data_parquet/demography.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11d1e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORization of POI\n",
    "pois_df[\"free_time_poi\"] = pois_df[[\"active_life\", \"arts_and_entertainment\", \"attractions_and_activities\", \"pets\", \"eat_and_drink\"]].sum(axis = 1)\n",
    "pois_df[\"bussines_hours_poi\"] = pois_df[[\"education\", \"business_to_business\", \"private_establishments_and_corporates\", \"professional_services\", \"real_estate\", \"financial_service\", \"health_and_medical\"]].sum(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51032120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h3res13', 'accommodation', 'active_life', 'arts_and_entertainment',\n",
       "       'attractions_and_activities', 'automotive', 'beauty_and_spa',\n",
       "       'business_to_business', 'eat_and_drink', 'education',\n",
       "       'financial_service', 'health_and_medical', 'home_service', 'mass_media',\n",
       "       'pets', 'private_establishments_and_corporates',\n",
       "       'professional_services', 'public_service_and_government', 'real_estate',\n",
       "       'religious_organization', 'retail', 'structure_and_geography', 'travel',\n",
       "       'free_time_poi', 'bussines_hours_poi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff73bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def distance_km(h1, h2):\n",
    "    loc1 = h3.cell_to_latlng(h1)\n",
    "    loc2 = h3.cell_to_latlng(h2)\n",
    "    return h3.great_circle_distance(loc1, loc2)\n",
    "\n",
    "\n",
    "def aggregate_by_dist(\n",
    "    agg_points,\n",
    "    data,\n",
    "    dist_metric,\n",
    "    allowed_distance=2,\n",
    "    agg_fun=np.mean,\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    for point in agg_points:\n",
    "        data_point = data.copy()\n",
    "        distances = data_point[\"h3res13\"].apply(lambda x: dist_metric(x, point))\n",
    "        nearby = data_point[distances < allowed_distance]\n",
    "\n",
    "        if nearby.empty:\n",
    "            continue\n",
    "\n",
    "        aggregated = nearby.drop(columns=[\"h3res13\"]).agg(agg_fun)\n",
    "        aggregated[\"h3res13\"] = point\n",
    "        results.append(aggregated)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "634ab437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def calculate_pois(dataset):\n",
    "    dfs0 = []\n",
    "    for dist in [0.5, 1, 2, 3, 5, 10]:\n",
    "        df0 = aggregate_by_dist(agg_points = dataset[\"h3res13\"].unique(), data = pois_df, dist_metric = distance_km, allowed_distance = dist, agg_fun = np.sum)\n",
    "        new_columns = {\n",
    "            col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "            for col in df0.columns\n",
    "        }\n",
    "        df0 = df0.rename(columns = new_columns)\n",
    "        dfs0.append(df0)\n",
    "    df_pois_agg = pd.concat(dfs0, axis = 1)\n",
    "    df_pois_agg[\"h3res13\"] = df_pois_agg[\"h3res13\"].bfill(axis = 1).ffill(axis = 1)\n",
    "    df_pois_agg = df_pois_agg.loc[:,~df_pois_agg.columns.duplicated()]\n",
    "    return df_pois_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a7972e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_train = calculate_pois(dataset = traffic_data_train)\n",
    "df_pois_test = calculate_pois(dataset = traffic_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b29b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_train = df_pois_train.fillna(0)\n",
    "df_pois_test = df_pois_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8d267",
   "metadata": {},
   "source": [
    "## demography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4f77e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_demography(dataset):\n",
    "    dfs0 = []\n",
    "    for dist in [0.5, 1, 2, 3]:\n",
    "        df0 = aggregate_by_dist(agg_points = dataset[\"h3res13\"].unique(), data = demo_df, dist_metric = distance_km, allowed_distance = dist, agg_fun = np.sum)\n",
    "        new_columns = {\n",
    "            col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "            for col in df0.columns\n",
    "        }\n",
    "        df0 = df0.rename(columns = new_columns)\n",
    "        dfs0.append(df0)\n",
    "    df_demo_agg = pd.concat(dfs0, axis = 1)\n",
    "    df_demo_agg = df_demo_agg.loc[:,~df_demo_agg.columns.duplicated()]\n",
    "    return df_demo_agg\n",
    "\n",
    "df_demo_train = calculate_pois(dataset = traffic_data_train)\n",
    "df_demo_test = calculate_pois(dataset = traffic_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "927ed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_train.to_parquet(\"dfs_processed/df_pois_agg.parquet\")\n",
    "df_demo_train.to_parquet(\"dfs_processed/df_demo_agg.parquet\")\n",
    "df_pois_test.to_parquet(\"dfs_processed_test/df_pois_agg_test.parquet\")\n",
    "df_demo_test.to_parquet(\"dfs_processed_test/df_demo_agg_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ad0d5",
   "metadata": {},
   "source": [
    "# A bit faster version for buildings and roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ced180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "pois_df = pd.read_parquet(\"../for_participants/data_parquet/pois.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9de8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h3\n",
    "\n",
    "def aggregate_by_dist(\n",
    "    agg_points,\n",
    "    data,\n",
    "    allowed_distance=2,\n",
    "    agg_fun=np.mean,\n",
    "):\n",
    "    all_h3s = pd.unique(np.concatenate([agg_points, data[\"h3res13\"].values]))\n",
    "    h3_to_coord = {h: h3.cell_to_latlng(h) for h in all_h3s}\n",
    "    def distance_km_cached(h1, h2):\n",
    "        loc1 = h3_to_coord[h1]\n",
    "        loc2 = h3_to_coord[h2]\n",
    "        return h3.great_circle_distance(loc1, loc2)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for point in agg_points:\n",
    "        distances = data[\"h3res13\"].apply(lambda x: distance_km_cached(x, point))\n",
    "        nearby = data[distances < allowed_distance]\n",
    "\n",
    "        if nearby.empty:\n",
    "            continue\n",
    "\n",
    "        aggregated = nearby.drop(columns=[\"h3res13\"]).agg(agg_fun)\n",
    "        aggregated[\"h3res13\"] = point\n",
    "        results.append(aggregated)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b43d3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = pd.read_parquet('../for_participants/data_parquet/roads.parquet')\n",
    "roads[\"roads_intensity_1\"] = roads[[\"motorway\", \"primary\", \"secondary\"]].sum(axis = 1)\n",
    "roads[\"roads_intensity_2\"] = roads[[\"tertiary\", \"residential\", \"living_street\", \"service\"]].sum(axis = 1)\n",
    "roads[\"roads_intensity_3\"] = roads[[\"track\", \"footway\", \"cycleway\", \"bridleway\", \"path\", \"steps\", \"pedestrian\"]].sum(axis = 1)\n",
    "roads = roads[[\"h3res13\", \"roads_intensity_1\", \"roads_intensity_2\", \"roads_intensity_3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e76aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def calculate_roads(dataset):\n",
    "    dfs0 = []\n",
    "    for dist in tqdm([0.1, 0.2, 0.5, 1]):\n",
    "        df0 = aggregate_by_dist(agg_points = dataset[\"h3res13\"].unique(), data = roads[[\"h3res13\", \"roads_intensity_1\", \"roads_intensity_2\", \"roads_intensity_3\"]], allowed_distance = dist, agg_fun = np.mean)\n",
    "        new_columns = {\n",
    "            col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "            for col in df0.columns\n",
    "        }\n",
    "        df0 = df0.rename(columns = new_columns)\n",
    "        dfs0.append(df0)\n",
    "    df_roads_agg = pd.concat(dfs0, axis = 1)\n",
    "    df_roads_agg = df_roads_agg.loc[:,~df_roads_agg.columns.duplicated()]\n",
    "    return df_roads_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca66a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [13:16<00:00, 199.23s/it]\n",
      "100%|██████████| 4/4 [09:44<00:00, 146.23s/it]\n"
     ]
    }
   ],
   "source": [
    "df_roads_train = calculate_roads(traffic_data_train)\n",
    "df_roads_test = calculate_roads(traffic_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3071e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roads_train.to_parquet(\"dfs_processed/df_roads_agg.parquet\")\n",
    "df_roads_test.to_parquet(\"dfs_processed_test/df_roads_agg_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e1f6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = pd.read_parquet('../for_participants/data_parquet/buildings.parquet')\n",
    "building_function_group = {\n",
    "    \"Single-Family Residence\": \"Residential\",\n",
    "    \"Multi-Family Residence\": \"Residential\",\n",
    "    \"Apartment\": \"Residential\",\n",
    "    \"Collected Dwelling Unit\": \"Residential\",\n",
    "    \"Hotel\": \"Residential\",\n",
    "    \"Tourist Accommodation Building\": \"Residential\",\n",
    "    \"Retail and Service Building\": \"Service\",\n",
    "    \"Hospitals and Medical Facility\": \"Service\",\n",
    "    \"Schools and Research Institute\": \"Service\",\n",
    "    \"Museums and Libraries\": \"Service\",\n",
    "    \"Cultural Facility\": \"Service\",\n",
    "    \"Cultural Public Facility\": \"Service\",\n",
    "    \"Place of Worship\": \"Service\",\n",
    "    \"Heritage Building\": \"Service\",\n",
    "    \"Car Park\": \"Service\",\n",
    "    \"Railway and Terminal Building\": \"Service\",\n",
    "    \"Office Building\": \"Work\",\n",
    "    \"Industrial Building\": \"Work\",\n",
    "    \"Silo or Warehouse\": \"Work\",\n",
    "    \"Agricultural Building\": \"Work\",\n",
    "    \"Non-Residential Building\": \"Work\",\n",
    "}\n",
    "\n",
    "buildings[\"building_function\"] = buildings[\"building_function\"].apply(lambda x: building_function_group[x]) #[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15e48add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "buildings = buildings.pivot_table(\n",
    "    index=\"h3res13\", columns=\"building_function\", values=\"building_area\", aggfunc=\"sum\", fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b59af4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_buildings(dataset):\n",
    "    dfs0 = []\n",
    "    for dist in tqdm([0.2, 0.5, 1, 1.5, 2]):\n",
    "        df0 = aggregate_by_dist(agg_points = dataset[\"h3res13\"].unique(), data = buildings[[\"h3res13\", \"Residential\", \"Service\", \"Work\"]], allowed_distance = dist, agg_fun = np.sum)\n",
    "        new_columns = {\n",
    "            col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "            for col in df0.columns\n",
    "        }\n",
    "        df0 = df0.rename(columns = new_columns)\n",
    "        dfs0.append(df0)\n",
    "    df_buildings_agg = pd.concat(dfs0, axis = 1)\n",
    "    df_buildings_agg = df_buildings_agg.loc[:,~df_buildings_agg.columns.duplicated()]\n",
    "    return df_buildings_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3373b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:22<00:00, 124.41s/it]\n"
     ]
    }
   ],
   "source": [
    "df_buildings_train = calculate_buildings(traffic_data_train)\n",
    "#df_buildings_test = calculate_buildings(traffic_data_test)\n",
    "df_buildings_train.to_parquet(\"dfs_processed/df_buildings_agg.parquet\")\n",
    "#df_buildings_test.to_parquet(\"dfs_processed_test/df_buildings_agg_test.parquet\")\n",
    "\n",
    "#df_buildings_agg.to_parquet(\"dfs_processed/df_buildings_agg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d06431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
