{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2590bca7",
   "metadata": {},
   "source": [
    "# aggregation of neighbourhood for each station from train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0c1c8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "traffic_data = pd.read_parquet(\"../for_participants/data_parquet/traffic_train.parquet\")\n",
    "pois_df = pd.read_parquet(\"../for_participants/data_parquet/pois.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7fca0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"8d1f5224541113f\"\n",
    "b = \"8d1f53d9a592cbf\"\n",
    "def distance_km(h1, h2):\n",
    "    loc1 = h3.cell_to_latlng(h1)\n",
    "    loc2 = h3.cell_to_latlng(h2)\n",
    "    return h3.great_circle_distance(loc1, loc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ff73bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_by_dist(\n",
    "    agg_points,\n",
    "    data,\n",
    "    dist_metric,\n",
    "    allowed_distance=2,\n",
    "    agg_fun=np.mean,\n",
    "):\n",
    "    results = []\n",
    "\n",
    "    for point in agg_points:\n",
    "        data_point = data.copy()\n",
    "        distances = data_point[\"h3res13\"].apply(lambda x: dist_metric(x, point))\n",
    "        nearby = data_point[distances < allowed_distance]\n",
    "\n",
    "        if nearby.empty:\n",
    "            continue\n",
    "\n",
    "        aggregated = nearby.drop(columns=[\"h3res13\"]).agg(agg_fun)\n",
    "        aggregated[\"h3res13\"] = point\n",
    "        results.append(aggregated)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "634ab437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dfs0 = []\n",
    "for dist in [0.5, 1, 2, 3, 5, 10]:\n",
    "    df0 = aggregate_by_dist(agg_points = traffic_data[\"h3res13\"].unique(), data = pois_df, dist_metric = distance_km, allowed_distance = dist, agg_fun = np.sum)\n",
    "    new_columns = {\n",
    "        col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "        for col in df0.columns\n",
    "    }\n",
    "    df0 = df0.rename(columns = new_columns)\n",
    "    dfs0.append(df0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7972e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_agg = pd.concat(dfs0, axis = 1)\n",
    "df_pois_agg = df_pois_agg.loc[:,~df_pois_agg.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4f77e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_parquet('../for_participants/data_parquet/demography.parquet')\n",
    "dfs0 = []\n",
    "for dist in [0.5, 1, 2, 3]:\n",
    "    df0 = aggregate_by_dist(agg_points = traffic_data[\"h3res13\"].unique(), data = demo, dist_metric = distance_km, allowed_distance = dist, agg_fun = np.sum)\n",
    "    new_columns = {\n",
    "        col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "        for col in df0.columns\n",
    "    }\n",
    "    df0 = df0.rename(columns = new_columns)\n",
    "    dfs0.append(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3eee35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_agg = pd.concat(dfs0, axis = 1)\n",
    "df_demo_agg = df_demo_agg.loc[:,~df_demo_agg.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "927ed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pois_agg.to_parquet(\"dfs_processed/df_pois_agg.parquet\")\n",
    "df_demo_agg.to_parquet(\"dfs_processed/df_demo_agg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb013afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b89ad0d5",
   "metadata": {},
   "source": [
    "# A bit faster version for buildings and roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ced180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h3\n",
    "traffic_data = pd.read_parquet(\"../for_participants/data_parquet/traffic_train.parquet\")\n",
    "pois_df = pd.read_parquet(\"../for_participants/data_parquet/pois.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h3\n",
    "\n",
    "def aggregate_by_dist(\n",
    "    agg_points,\n",
    "    data,\n",
    "    allowed_distance=2,\n",
    "    agg_fun=np.mean,\n",
    "):\n",
    "    all_h3s = pd.unique(np.concatenate([agg_points, data[\"h3res13\"].values]))\n",
    "    h3_to_coord = {h: h3.cell_to_latlng(h) for h in all_h3s}\n",
    "    def distance_km_cached(h1, h2):\n",
    "        loc1 = h3_to_coord[h1]\n",
    "        loc2 = h3_to_coord[h2]\n",
    "        return h3.great_circle_distance(loc1, loc2)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for point in agg_points:\n",
    "        distances = data[\"h3res13\"].apply(lambda x: distance_km_cached(x, point))\n",
    "        nearby = data[distances < allowed_distance]\n",
    "\n",
    "        if nearby.empty:\n",
    "            continue\n",
    "\n",
    "        aggregated = nearby.drop(columns=[\"h3res13\"]).agg(agg_fun)\n",
    "        aggregated[\"h3res13\"] = point\n",
    "        results.append(aggregated)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads = pd.read_parquet('../for_participants/data_parquet/roads.parquet')\n",
    "roads[\"roads_intensity_1\"] = roads[[\"motorway\", \"primary\", \"secondary\"]].sum(axis = 1)\n",
    "roads[\"roads_intensity_2\"] = roads[[\"tertiary\", \"residential\", \"living_street\", \"service\"]].sum(axis = 1)\n",
    "roads[\"roads_intensity_3\"] = roads[[\"track\", \"footway\", \"cycleway\", \"bridleway\", \"path\", \"steps\", \"pedestrian\"]].sum(axis = 1)\n",
    "roads = roads[[\"h3res13\", \"roads_intensity_1\", \"roads_intensity_2\", \"roads_intensity_3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "dfs0 = []\n",
    "for dist in tqdm([0.2, 0.5, 1]):\n",
    "    df0 = aggregate_by_dist(agg_points = traffic_data[\"h3res13\"].unique(), data = roads[[\"h3res13\", \"roads_intensity_1\", \"roads_intensity_2\", \"roads_intensity_3\"]], allowed_distance = dist, agg_fun = np.mean)\n",
    "    new_columns = {\n",
    "        col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "        for col in df0.columns\n",
    "    }\n",
    "    df0 = df0.rename(columns = new_columns)\n",
    "    dfs0.append(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca66a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roads_agg = pd.concat(dfs0, axis = 1)\n",
    "df_roads_agg = df_buildings_agg.loc[:,~df_buildings_agg.columns.duplicated()]\n",
    "df_roads_agg.to_parquet(\"dfs_processed/df_roads_agg.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = pd.read_parquet('../for_participants/data_parquet/buildings.parquet')\n",
    "building_function_group = {\n",
    "    \"Single-Family Residence\": \"Residential\",\n",
    "    \"Multi-Family Residence\": \"Residential\",\n",
    "    \"Apartment\": \"Residential\",\n",
    "    \"Collected Dwelling Unit\": \"Residential\",\n",
    "    \"Hotel\": \"Residential\",\n",
    "    \"Tourist Accommodation Building\": \"Residential\",\n",
    "    \"Retail and Service Building\": \"Service\",\n",
    "    \"Hospitals and Medical Facility\": \"Service\",\n",
    "    \"Schools and Research Institute\": \"Service\",\n",
    "    \"Museums and Libraries\": \"Service\",\n",
    "    \"Cultural Facility\": \"Service\",\n",
    "    \"Cultural Public Facility\": \"Service\",\n",
    "    \"Place of Worship\": \"Service\",\n",
    "    \"Heritage Building\": \"Service\",\n",
    "    \"Car Park\": \"Service\",\n",
    "    \"Railway and Terminal Building\": \"Service\",\n",
    "    \"Office Building\": \"Work\",\n",
    "    \"Industrial Building\": \"Work\",\n",
    "    \"Silo or Warehouse\": \"Work\",\n",
    "    \"Agricultural Building\": \"Work\",\n",
    "    \"Non-Residential Building\": \"Work\",\n",
    "}\n",
    "\n",
    "buildings[\"building_function\"] = buildings[\"building_function\"].apply(lambda x: building_function_group[x]) #[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e48add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "buildings = buildings.pivot_table(\n",
    "    index=\"h3res13\",                   # grupuj po lokalizacji\n",
    "    columns=\"building_function\",       # przekształć kategorie w kolumny\n",
    "    values=\"building_area\",            # wartości to powierzchnia\n",
    "    aggfunc=\"sum\",                     # lub np. \"mean\" / \"max\"\n",
    "    fill_value=0                       # brak danych = 0\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59af4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs0 = []\n",
    "for dist in tqdm([0.5, 1, 1.5, 2]):\n",
    "    df0 = aggregate_by_dist(agg_points = traffic_data[\"h3res13\"].unique(), data = buildings[[\"h3res13\", \"Residential\", \"Service\", \"Work\"]], allowed_distance = dist, agg_fun = np.sum)\n",
    "    new_columns = {\n",
    "        col: col + \"_\" + str(dist) if col != \"h3res13\" else col\n",
    "        for col in df0.columns\n",
    "    }\n",
    "    df0 = df0.rename(columns = new_columns)\n",
    "    dfs0.append(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buildings_agg = pd.concat(dfs0, axis = 1)\n",
    "df_buildings_agg = df_buildings_agg.loc[:,~df_buildings_agg.columns.duplicated()]\n",
    "df_buildings_agg.to_parquet(\"dfs_processed/df_buildings_agg.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
